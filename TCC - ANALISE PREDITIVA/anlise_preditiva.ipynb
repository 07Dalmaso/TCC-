{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c42209-6102-4fe5-ae4c-d95b1bd167b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Imports do Projeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac274557-5538-462b-8c2a-b58e36f19383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbbf923-db81-49aa-8384-cafa19f5e474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Anos análisado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cad6aa7-46e3-4923-98a6-2f952173d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "anos = ['2019', '2020', '2021', '2022', '2023']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209c5cb-231a-4cfd-a553-d674f02478b5",
   "metadata": {},
   "source": [
    "# **Pré-processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6559cf-9230-4772-b54b-8ec98bad8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 6-2019-CAMPOSDOSGOYTACAZES.csv processado. Novo arquivo salvo como 2019-formatado\\6-2019-CAMPOSDOSGOYTACAZES.csv.\n",
      "Arquivo 7-2019-ANGRADOSREIS.csv processado. Novo arquivo salvo como 2019-formatado\\7-2019-ANGRADOSREIS.csv.\n",
      "Arquivo 8-2019-RIODEJANEIRO.csv processado. Novo arquivo salvo como 2019-formatado\\8-2019-RIODEJANEIRO.csv.\n",
      "Arquivo 9-2019-VALENCA.csv processado. Novo arquivo salvo como 2019-formatado\\9-2019-VALENCA.csv.\n",
      "Arquivo 6-2020-CAMPOSDOSGOYTACAZES.csv processado. Novo arquivo salvo como 2020-formatado\\6-2020-CAMPOSDOSGOYTACAZES.csv.\n",
      "Arquivo 7-2020-ANGRADOSREIS.csv processado. Novo arquivo salvo como 2020-formatado\\7-2020-ANGRADOSREIS.csv.\n",
      "Arquivo 8-2020-RIODEJANEIRO.csv processado. Novo arquivo salvo como 2020-formatado\\8-2020-RIODEJANEIRO.csv.\n",
      "Arquivo 9-2020-VALENCA.csv processado. Novo arquivo salvo como 2020-formatado\\9-2020-VALENCA.csv.\n",
      "Arquivo 6-2021-CAMPOSDOSGOYTACAZES.csv processado. Novo arquivo salvo como 2021-formatado\\6-2021-CAMPOSDOSGOYTACAZES.csv.\n",
      "Arquivo 7-2021-ANGRADOSREIS.csv processado. Novo arquivo salvo como 2021-formatado\\7-2021-ANGRADOSREIS.csv.\n",
      "Arquivo 8-2021-RIODEJANEIRO.csv processado. Novo arquivo salvo como 2021-formatado\\8-2021-RIODEJANEIRO.csv.\n",
      "Arquivo 9-2021-VALENCA.csv processado. Novo arquivo salvo como 2021-formatado\\9-2021-VALENCA.csv.\n",
      "Arquivo 6-2022-CAMPOSDOSGOYTACAZES.csv processado. Novo arquivo salvo como 2022-formatado\\6-2022-CAMPOSDOSGOYTACAZES.csv.\n",
      "Arquivo 7-2022-ANGRADOSREIS.csv processado. Novo arquivo salvo como 2022-formatado\\7-2022-ANGRADOSREIS.csv.\n",
      "Arquivo 8-2022-RIODEJANEIRO.csv processado. Novo arquivo salvo como 2022-formatado\\8-2022-RIODEJANEIRO.csv.\n",
      "Arquivo 9-2022-VALENCA.csv processado. Novo arquivo salvo como 2022-formatado\\9-2022-VALENCA.csv.\n",
      "Arquivo 6-2023-CAMPOSDOSGOYTACAZES.csv processado. Novo arquivo salvo como 2023-formatado\\6-2023-CAMPOSDOSGOYTACAZES.csv.\n",
      "Arquivo 7-2023-ANGRADOSREIS.csv processado. Novo arquivo salvo como 2023-formatado\\7-2023-ANGRADOSREIS.csv.\n",
      "Arquivo 8-2023-RIO DE JANEIRO.csv processado. Novo arquivo salvo como 2023-formatado\\8-2023-RIO DE JANEIRO.csv.\n",
      "Arquivo 9-2023-VALENCIA.csv processado. Novo arquivo salvo como 2023-formatado\\9-2023-VALENCIA.csv.\n"
     ]
    }
   ],
   "source": [
    "colunas_desejadas = [\n",
    "    'Data', \n",
    "    'Hora UTC', \n",
    "    'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)', \n",
    "    'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)', \n",
    "    'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)', \n",
    "    'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)', \n",
    "    'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)'\n",
    "]\n",
    "\n",
    "def processar_csv(diretorio, arquivo, diretorio_novo):\n",
    "    caminho_arquivo = os.path.join(diretorio, arquivo)\n",
    "    df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    colunas_presentes = [coluna for coluna in colunas_desejadas if coluna in df.columns]\n",
    "    df_filtrado = df[colunas_presentes]\n",
    "\n",
    "    novo_caminho = os.path.join(diretorio_novo, arquivo)\n",
    "    df_filtrado.to_csv(novo_caminho, index=False)\n",
    "\n",
    "    print(f'Arquivo {arquivo} processado. Novo arquivo salvo como {novo_caminho}.')\n",
    "\n",
    "for ano in anos:\n",
    "    diretorio = ano\n",
    "    diretorio_novo = f'{ano}-formatado'\n",
    "    \n",
    "    os.makedirs(diretorio_novo, exist_ok=True)\n",
    "\n",
    "    arquivos_csv = [f for f in os.listdir(diretorio) if f.endswith('.csv')]\n",
    "\n",
    "    for arquivo in arquivos_csv:\n",
    "        processar_csv(diretorio, arquivo, diretorio_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f7fb4e-2979-49b6-bd3b-6a78eba04e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: medias_semanal\\medias_semanal_2019-formatado_6-2019-CAMPOSDOSGOYTACAZES.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2019-formatado_7-2019-ANGRADOSREIS.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2019-formatado_8-2019-RIODEJANEIRO.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2019-formatado_9-2019-VALENCA.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2020-formatado_6-2020-CAMPOSDOSGOYTACAZES.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2020-formatado_7-2020-ANGRADOSREIS.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2020-formatado_8-2020-RIODEJANEIRO.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2020-formatado_9-2020-VALENCA.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2021-formatado_6-2021-CAMPOSDOSGOYTACAZES.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2021-formatado_7-2021-ANGRADOSREIS.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2021-formatado_8-2021-RIODEJANEIRO.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2021-formatado_9-2021-VALENCA.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2022-formatado_6-2022-CAMPOSDOSGOYTACAZES.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2022-formatado_7-2022-ANGRADOSREIS.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2022-formatado_8-2022-RIODEJANEIRO.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2022-formatado_9-2022-VALENCA.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2023-formatado_6-2023-CAMPOSDOSGOYTACAZES.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2023-formatado_7-2023-ANGRADOSREIS.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2023-formatado_8-2023-RIO DE JANEIRO.csv\n",
      "Salvo: medias_semanal\\medias_semanal_2023-formatado_9-2023-VALENCIA.csv\n"
     ]
    }
   ],
   "source": [
    "anos = ['2019-formatado', '2020-formatado', '2021-formatado', '2022-formatado', '2023-formatado']\n",
    "\n",
    "def processar_csv(arquivo_csv, ano):\n",
    "    df = pd.read_csv(arquivo_csv, sep=',') \n",
    "    \n",
    "    df['Data'] = pd.to_datetime(df['Data'], format='%d/%m/%Y')\n",
    "    \n",
    "    colunas_para_converter = [\n",
    "        'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)', \n",
    "        'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)', \n",
    "        'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)', \n",
    "        'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)', \n",
    "        'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)'\n",
    "    ]\n",
    "    \n",
    "    for coluna in colunas_para_converter:\n",
    "        df[coluna] = pd.to_numeric(df[coluna], errors='coerce')\n",
    "    \n",
    "    df['Semana'] = df['Data'].dt.isocalendar().week\n",
    "    medias_semanal = df.groupby('Semana').agg({\n",
    "        'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)': 'mean',\n",
    "        'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)': 'mean',\n",
    "        'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)': 'mean',\n",
    "        'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)': 'mean',\n",
    "        'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    nova_pasta = 'medias_semanal'\n",
    "    os.makedirs(nova_pasta, exist_ok=True) \n",
    "    \n",
    "    nome_arquivo_novo = os.path.join(nova_pasta, f'medias_semanal_{ano}_{os.path.basename(arquivo_csv)}')\n",
    "    \n",
    "    medias_semanal.to_csv(nome_arquivo_novo, index=False)\n",
    "    print(f'Salvo: {nome_arquivo_novo}')\n",
    "\n",
    "for ano in anos:\n",
    "    for arquivo in os.listdir(ano):\n",
    "        if arquivo.endswith('.csv'):\n",
    "            caminho_arquivo = os.path.join(ano, arquivo)\n",
    "            processar_csv(caminho_arquivo, ano)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f4894-1da3-4983-aea4-9c975b867f49",
   "metadata": {},
   "source": [
    "**Porcesso para adcionar 0 casos as semanas faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12edf7c0-1560-4913-9d58-39d5046685a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído! Semanas faltantes preenchidas com 0 nos arquivos originais.\n"
     ]
    }
   ],
   "source": [
    "pasta_arquivos = 'casos_dengue_rj'\n",
    "\n",
    "semanas_padrao = list(range(1, 53))\n",
    "\n",
    "for arquivo in os.listdir(pasta_arquivos):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        caminho_arquivo = os.path.join(pasta_arquivos, arquivo)\n",
    "        \n",
    "        df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "        if 'Semana epidemiológica dos sintomas' in df.columns and 'Casos notificados' in df.columns:\n",
    "            df = df[df['Semana epidemiológica dos sintomas'] != 'Total']\n",
    "            \n",
    "            df['Semana epidemiológica dos sintomas'] = pd.to_numeric(df['Semana epidemiológica dos sintomas'], errors='coerce')\n",
    "            df_completo = pd.DataFrame({'Semana epidemiológica dos sintomas': semanas_padrao})\n",
    "            df = df_completo.merge(df, on='Semana epidemiológica dos sintomas', how='left').fillna(0)\n",
    "\n",
    "            df['Casos notificados'] = df['Casos notificados'].astype(int)\n",
    "\n",
    "            df.to_csv(caminho_arquivo, index=False)\n",
    "\n",
    "print(\"Processamento concluído! Semanas faltantes preenchidas com 0 nos arquivos originais.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df254e8-65d2-4ba8-bb02-483b1508082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'extremos_dados.csv' criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "caminho_arquivos = 'medias_semanal/'\n",
    "\n",
    "extremos = {\n",
    "    \"PRECIPITAÇÃO TOTAL, HORÁRIO (mm)\": {\"max\": float('-inf'), \"min\": float('inf')},\n",
    "    \"TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)\": {\"max\": float('-inf'), \"min\": float('inf')},\n",
    "    \"TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)\": {\"max\": float('-inf'), \"min\": float('inf')},\n",
    "    \"UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)\": {\"max\": float('-inf'), \"min\": float('inf')},\n",
    "    \"UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)\": {\"max\": float('-inf'), \"min\": float('inf')}\n",
    "}\n",
    "\n",
    "for nome_arquivo in os.listdir(caminho_arquivos):\n",
    "    caminho_completo = os.path.join(caminho_arquivos, nome_arquivo)\n",
    "    \n",
    "    if nome_arquivo.endswith('.csv'):\n",
    "        df = pd.read_csv(caminho_completo)\n",
    "        \n",
    "        for coluna in extremos.keys():\n",
    "            extremos[coluna]['max'] = max(extremos[coluna]['max'], df[coluna].max())\n",
    "            extremos[coluna]['min'] = min(extremos[coluna]['min'], df[coluna].min())\n",
    "\n",
    "df_extremos = pd.DataFrame({\n",
    "    \"Métrica\": list(extremos.keys()),\n",
    "    \"Máximo\": [extremos[col][\"max\"] for col in extremos],\n",
    "    \"Mínimo\": [extremos[col][\"min\"] for col in extremos]\n",
    "})\n",
    "\n",
    "df_extremos.to_csv('extremos_dados.csv', index=False)\n",
    "print(\"Arquivo 'extremos_dados.csv' criado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d00ec581-4946-41e1-b81b-16b468111d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo medias_semanal_2019-formatado_6-2019-CAMPOSDOSGOYTACAZES.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2019-formatado_7-2019-ANGRADOSREIS.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2019-formatado_8-2019-RIODEJANEIRO.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2019-formatado_9-2019-VALENCA.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2020-formatado_6-2020-CAMPOSDOSGOYTACAZES.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2020-formatado_7-2020-ANGRADOSREIS.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2020-formatado_8-2020-RIODEJANEIRO.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2020-formatado_9-2020-VALENCA.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2021-formatado_6-2021-CAMPOSDOSGOYTACAZES.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2021-formatado_7-2021-ANGRADOSREIS.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2021-formatado_8-2021-RIODEJANEIRO.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2021-formatado_9-2021-VALENCA.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2022-formatado_6-2022-CAMPOSDOSGOYTACAZES.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2022-formatado_7-2022-ANGRADOSREIS.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2022-formatado_8-2022-RIODEJANEIRO.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2022-formatado_9-2022-VALENCA.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2023-formatado_6-2023-CAMPOSDOSGOYTACAZES.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2023-formatado_7-2023-ANGRADOSREIS.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2023-formatado_8-2023-RIO DE JANEIRO.csv normalizado e salvo em medias_semanal_normalizados/\n",
      "Arquivo medias_semanal_2023-formatado_9-2023-VALENCIA.csv normalizado e salvo em medias_semanal_normalizados/\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'medias_semanal/'\n",
    "output_dir = 'medias_semanal_normalizados/'\n",
    "extremos_file = 'extremos_dados.csv'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "extremos_df = pd.read_csv(extremos_file)\n",
    "extremos = {}\n",
    "\n",
    "for _, row in extremos_df.iterrows():\n",
    "    coluna = row['Métrica']\n",
    "    extremos[coluna] = {'min': row['Mínimo'], 'max': row['Máximo']}\n",
    "\n",
    "def normalizar(valor, min_val, max_val):\n",
    "    if max_val - min_val == 0:\n",
    "        return 0\n",
    "    return (valor - min_val) / (max_val - min_val)\n",
    "\n",
    "for arquivo in os.listdir(input_dir):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(input_dir, arquivo))\n",
    "        \n",
    "        for coluna, limite in extremos.items():\n",
    "            if coluna in df.columns:\n",
    "                min_val, max_val = limite['min'], limite['max']\n",
    "                df[coluna] = df[coluna].apply(lambda x: normalizar(x, min_val, max_val))\n",
    "        \n",
    "        df.to_csv(os.path.join(output_dir, arquivo), index=False)\n",
    "        print(f'Arquivo {arquivo} normalizado e salvo em {output_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87682d9e-45eb-4778-a1f9-014b76a29302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo unificado criado com sucesso em: casos_dengue_rj_unificado/dados_dengue_unificado.csv\n",
      "Arquivo criado para a região 'AR' em: casos_dengue_rj_unificado/dados_dengue_AR.csv\n",
      "Arquivo criado para a região 'CG' em: casos_dengue_rj_unificado/dados_dengue_CG.csv\n",
      "Arquivo criado para a região 'RJ' em: casos_dengue_rj_unificado/dados_dengue_RJ.csv\n",
      "Arquivo criado para a região 'VA' em: casos_dengue_rj_unificado/dados_dengue_VA.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "source_path = 'casos_dengue_rj/'\n",
    "destination_folder = 'casos_dengue_rj_unificado/'\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# Ler e unificar os dados\n",
    "for file_name in os.listdir(source_path):\n",
    "    if file_name.startswith(\"corrigido\") and file_name.endswith(\".csv\"):\n",
    "        year = file_name.split('_')[1][7:11]\n",
    "        region = file_name.split('_')[-1].split('.')[0]\n",
    "        file_path = os.path.join(source_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Ano'] = year\n",
    "        df['Regiao'] = region\n",
    "        \n",
    "        all_data.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Salvar o arquivo unificado\n",
    "output_file = os.path.join(destination_folder, 'dados_dengue_unificado.csv')\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Arquivo unificado criado com sucesso em: {output_file}\")\n",
    "\n",
    "# Criar arquivos separados por região\n",
    "for region, group in combined_df.groupby('Regiao'):\n",
    "    region_file = os.path.join(destination_folder, f'dados_dengue_{region}.csv')\n",
    "    group.to_csv(region_file, index=False)\n",
    "    print(f\"Arquivo criado para a região '{region}' em: {region_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea59be9-80f9-4213-8346-0a8ca6af899c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4b0d62-4811-41c4-b3c2-0e7aa5bf76ab",
   "metadata": {},
   "source": [
    "# **Análise Preditiva**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d7524-2530-4511-9143-1a54ceb4ee31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
